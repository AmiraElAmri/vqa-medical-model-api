<<<<<<< HEAD
# ðŸ¥ Medical Multimodal AI Model: Gastroenterology Diagnosis

This project implements a **multimodal Visual Question Answering (VQA)** model for medical diagnosis based on **endoscopic images and natural language questions**

ðŸŽ¯ The model combines:
- **MobileNetV2** for image feature extraction
- **BioClinical-BERT** for medical question encoding
- A custom **MLP classifier** to predict answers such as `"polyp"`, `"ulcer"`, `"inflammation"` etc.

âœ… Designed to be used in a mobile application via Flask API (`/predict`) and called from **Flutter** using HTTP requests

---

## ðŸ§  Project Overview

This repository contains the trained model, API, and configuration files needed to deploy a medical AI model capable of answering diagnostic questions from endoscopic images.

---

## ðŸ“¦ Folder Structure
=======
# vqa-medical-model-api
"ModÃ¨le IA multimodal (MobileNetV2 + BioClinical-BERT) pour rÃ©pondre Ã  des questions mÃ©dicales Ã  partir d'images endoscopiques"
>>>>>>> 01258f46b997627a3115fcd34955150fd8ae9f44
